{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/rmb456/multif0/deepsalience\n"
     ]
    }
   ],
   "source": [
    "cd ../deepsalience/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import multitask_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Reshape, Lambda, Permute\n",
    "from keras.layers.merge import Concatenate, Multiply\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input_shape = (None, None, 5)\n",
    "    y0 = Input(shape=input_shape)\n",
    "\n",
    "    y1_pitch = Conv2D(\n",
    "        32, (5, 5), padding='same', activation='relu', name='pitch_layer1')(y0) #32\n",
    "    y1a_pitch = BatchNormalization()(y1_pitch)\n",
    "    y2_pitch = Conv2D(\n",
    "        32, (5, 5), padding='same', activation='relu', name='pitch_layer2')(y1a_pitch) #32\n",
    "    y2a_pitch = BatchNormalization()(y2_pitch)\n",
    "    y3_pitch = Conv2D(32, (3, 3), padding='same', activation='relu', name='smoothy2')(y2a_pitch) #32\n",
    "    y3a_pitch = BatchNormalization()(y3_pitch)\n",
    "    y4_pitch = Conv2D(8, (70, 3), padding='same', activation='relu', name='distribute')(y3a_pitch) #8\n",
    "    y4a_pitch = BatchNormalization()(y4_pitch)\n",
    "\n",
    "    y_multif0 = Conv2D(\n",
    "        1, (1, 1), padding='same', activation='sigmoid', name='multif0_presqueeze')(y4a_pitch)\n",
    "    multif0 = Lambda(lambda x: K.squeeze(x, axis=3), name='multif0')(y_multif0)\n",
    "\n",
    "    y_mask = Multiply(name='mask')([y_multif0, y0])\n",
    "    y1_timbre = Conv2D(\n",
    "        512, (2, 3), padding='same', activation='relu', name='timbre_layer1')(y_mask) #512\n",
    "    y1a_timbre = BatchNormalization()(y1_timbre)\n",
    "\n",
    "    y_concat = Concatenate(name='timbre_and_pitch')([y_multif0, y1a_timbre])\n",
    "    ya_concat = BatchNormalization()(y_concat)\n",
    "\n",
    "    y_mel_feat = Conv2D(\n",
    "        1, (3, 3), padding='same', activation='relu', name='melody_filters')(ya_concat) #32\n",
    "    ya_mel_feat = BatchNormalization()(y_mel_feat)\n",
    "    y_mel_feat2 = Conv2D(\n",
    "        1, (3, 3), padding='same', activation='relu', name='melody_filters2')(ya_mel_feat)#32\n",
    "    ya_mel_feat2 = BatchNormalization()(y_mel_feat2)\n",
    "    y_mel_feat3 = Conv2D(\n",
    "        1, (240, 1), padding='same', activation='relu', name='melody_filters3')(ya_mel_feat2) # 8\n",
    "    ya_mel_feat3 = BatchNormalization()(y_mel_feat3)\n",
    "    y_mel_feat4 = Conv2D(\n",
    "        1, (7, 7), padding='same', activation='relu', name='melody_filters4')(ya_mel_feat3) # 16\n",
    "    ya_mel_feat4 = BatchNormalization()(y_mel_feat4)\n",
    "    y_mel_feat5 = Conv2D(\n",
    "        1, (7, 7), padding='same', activation='relu', name='melody_filters5')(ya_mel_feat4) #16\n",
    "    ya_mel_feat5 = BatchNormalization()(y_mel_feat5)\n",
    "\n",
    "    y_bass_feat = Conv2D(\n",
    "        1, (3, 3), padding='same', activation='relu', name='bass_filters')(ya_concat) #32\n",
    "    ya_bass_feat = BatchNormalization()(y_bass_feat)\n",
    "    y_bass_feat2 = Conv2D(\n",
    "        1, (3, 3), padding='same', activation='relu', name='bass_filters2')(ya_bass_feat) #32\n",
    "    ya_bass_feat2 = BatchNormalization()(y_bass_feat2)\n",
    "    y_bass_feat3 = Conv2D(\n",
    "        1, (240, 1), padding='same', activation='relu', name='bass_filters3')(ya_bass_feat2) #8\n",
    "    ya_bass_feat3 = BatchNormalization()(y_bass_feat3)\n",
    "    y_bass_feat4 = Conv2D(\n",
    "        1, (7, 7), padding='same', activation='relu', name='bass_filters4')(ya_bass_feat3) #16\n",
    "    ya_bass_feat4 = BatchNormalization()(y_bass_feat4)\n",
    "    y_bass_feat5 = Conv2D(\n",
    "        1, (7, 7), padding='same', activation='relu', name='bass_filters5')(ya_bass_feat4) #16\n",
    "    ya_bass_feat5 = BatchNormalization()(y_bass_feat5)\n",
    "\n",
    "    y_vocal_feat = Conv2D(\n",
    "        1, (3, 3), padding='same', activation='relu', name='vocal_filters')(ya_concat) #32\n",
    "    ya_vocal_feat = BatchNormalization()(y_vocal_feat)\n",
    "    y_vocal_feat2 = Conv2D(\n",
    "        1, (3, 3), padding='same', activation='relu', name='vocal_filters2')(ya_vocal_feat) #32\n",
    "    ya_vocal_feat2 = BatchNormalization()(y_vocal_feat2)\n",
    "    y_vocal_feat3 = Conv2D(\n",
    "        1, (240, 1), padding='same', activation='relu', name='vocal_filters3')(ya_vocal_feat2) #8\n",
    "    ya_vocal_feat3 = BatchNormalization()(y_vocal_feat3)\n",
    "    y_vocal_feat4 = Conv2D(\n",
    "        1, (7, 7), padding='same', activation='relu', name='vocal_filters4')(ya_vocal_feat3) # 16\n",
    "    ya_vocal_feat4 = BatchNormalization()(y_vocal_feat4)\n",
    "    y_vocal_feat5 = Conv2D(\n",
    "        1, (7, 7), padding='same', activation='relu', name='vocal_filters5')(ya_vocal_feat4) #16\n",
    "    ya_vocal_feat5 = BatchNormalization()(y_vocal_feat5)\n",
    "\n",
    "    y_melody = Conv2D(\n",
    "        1, (1, 1), padding='same', activation='sigmoid', name='melody_presqueeze')(ya_mel_feat5)\n",
    "    melody = Lambda(lambda x: K.squeeze(x, axis=3), name='melody')(y_melody)\n",
    "\n",
    "    y_bass = Conv2D(\n",
    "        1, (1, 1), padding='same', activation='sigmoid', name='bass_presqueeze')(ya_bass_feat5)\n",
    "    bass = Lambda(lambda x: K.squeeze(x, axis=3), name='bass')(y_bass)\n",
    "\n",
    "    y_vocal = Conv2D(\n",
    "        1, (1, 1), padding='same', activation='sigmoid', name='vocal_presqueeze')(ya_vocal_feat5)\n",
    "    vocal = Lambda(lambda x: K.squeeze(x, axis=3), name='vocal')(y_vocal)\n",
    "\n",
    "    model = Model(inputs=y0, outputs=[multif0, melody, bass, vocal])\n",
    "\n",
    "    model.summary(line_length=120)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                           Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      "input_1 (InputLayer)                   (None, None, None, 5)      0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "pitch_layer1 (Conv2D)                  (None, None, None, 1)      126                                                   \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNormalizat (None, None, None, 1)      4                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "pitch_layer2 (Conv2D)                  (None, None, None, 1)      26                                                    \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNormalizat (None, None, None, 1)      4                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "smoothy2 (Conv2D)                      (None, None, None, 1)      10                                                    \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNormalizat (None, None, None, 1)      4                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "distribute (Conv2D)                    (None, None, None, 1)      211                                                   \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNormalizat (None, None, None, 1)      4                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "multif0_presqueeze (Conv2D)            (None, None, None, 1)      2                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "mask (Multiply)                        (None, None, None, 5)      0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "timbre_layer1 (Conv2D)                 (None, None, None, 2)      62                                                    \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNormalizat (None, None, None, 2)      8                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "timbre_and_pitch (Concatenate)         (None, None, None, 3)      0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNormalizat (None, None, None, 3)      12                                                    \n",
      "________________________________________________________________________________________________________________________\n",
      "vocal_filters (Conv2D)                 (None, None, None, 1)      28                                                    \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNormalizat (None, None, None, 1)      4                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "vocal_filters2 (Conv2D)                (None, None, None, 1)      10                                                    \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNormalizat (None, None, None, 1)      4                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "vocal_filters3 (Conv2D)                (None, None, None, 1)      241                                                   \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNormalizat (None, None, None, 1)      4                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "vocal_filters4 (Conv2D)                (None, None, None, 1)      50                                                    \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNormaliza (None, None, None, 1)      4                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "vocal_filters5 (Conv2D)                (None, None, None, 1)      50                                                    \n",
      "________________________________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNormaliza (None, None, None, 1)      4                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "vocal_presqueeze (Conv2D)              (None, None, None, 1)      2                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "multif0 (Lambda)                       (None, None, None)         0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "vocal (Lambda)                         (None, None, None)         0                                                     \n",
      "========================================================================================================================\n",
      "Total params: 874\n",
      "Trainable params: 846\n",
      "Non-trainable params: 28\n",
      "________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "output_path = '../experiment_output/trialrun_multitask'\n",
    "tasks = ['multif0', 'vocal']\n",
    "data_types = ['XA', 'XD']\n",
    "loss_weights = {'multif0': 2.0, 'vocal': 1.0} #{'multif0': 2.0, 'melody': 1.0, 'bass': 1.0, 'vocal': 1.0}\n",
    "sample_weight_mode = {'multif0': None, 'vocal': None}#{'multif0': None, 'melody': None, 'bass': None, 'vocal': None}\n",
    "task_indices = {'multif0': 0, 'vocal': 1}#{'multif0': 0, 'melody': 1, 'bass': 2, 'vocal': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 2.2840 - multif0_loss: 0.6962 - vocal_loss: 0.8916 - multif0_mean_squared_error: 0.2497 - multif0_soft_binary_accuracy: 0.3773 - vocal_mean_squared_error: 0.3510 - vocal_soft_binary_accuracy: 0.2472 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 00000: val_loss improved from inf to 2.07744, saving model to ../experiment_output/trialrun_multitask/model_weights.h5\n",
      "10/10 [==============================] - 5s - loss: 2.2816 - multif0_loss: 0.6959 - vocal_loss: 0.8898 - multif0_mean_squared_error: 0.2496 - multif0_soft_binary_accuracy: 0.3889 - vocal_mean_squared_error: 0.3503 - vocal_soft_binary_accuracy: 0.2458 - val_loss: 2.0774 - val_multif0_loss: 0.6906 - val_vocal_loss: 0.6962 - val_multif0_mean_squared_error: 0.2464 - val_multif0_soft_binary_accuracy: 0.9895 - val_vocal_mean_squared_error: 0.2505 - val_vocal_soft_binary_accuracy: 0.0223\n",
      "Epoch 2/5\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 2.2369 - multif0_loss: 0.6900 - vocal_loss: 0.8570 - multif0_mean_squared_error: 0.2472 - multif0_soft_binary_accuracy: 0.4828 - vocal_mean_squared_error: 0.3357 - vocal_soft_binary_accuracy: 0.2164\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 00001: val_loss improved from 2.07744 to 2.06710, saving model to ../experiment_output/trialrun_multitask/model_weights.h5\n",
      "10/10 [==============================] - 0s - loss: 2.2349 - multif0_loss: 0.6896 - vocal_loss: 0.8557 - multif0_mean_squared_error: 0.2470 - multif0_soft_binary_accuracy: 0.4869 - vocal_mean_squared_error: 0.3351 - vocal_soft_binary_accuracy: 0.2182 - val_loss: 2.0671 - val_multif0_loss: 0.6874 - val_vocal_loss: 0.6922 - val_multif0_mean_squared_error: 0.2449 - val_multif0_soft_binary_accuracy: 0.9903 - val_vocal_mean_squared_error: 0.2485 - val_vocal_soft_binary_accuracy: 0.0975\n",
      "Epoch 3/5\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 2.1918 - multif0_loss: 0.6836 - vocal_loss: 0.8247 - multif0_mean_squared_error: 0.2439 - multif0_soft_binary_accuracy: 0.4391 - vocal_mean_squared_error: 0.3185 - vocal_soft_binary_accuracy: 0.1881\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 00002: val_loss improved from 2.06710 to 2.05586, saving model to ../experiment_output/trialrun_multitask/model_weights.h5\n",
      "10/10 [==============================] - 0s - loss: 2.1915 - multif0_loss: 0.6833 - vocal_loss: 0.8249 - multif0_mean_squared_error: 0.2437 - multif0_soft_binary_accuracy: 0.4493 - vocal_mean_squared_error: 0.3188 - vocal_soft_binary_accuracy: 0.1905 - val_loss: 2.0559 - val_multif0_loss: 0.6838 - val_vocal_loss: 0.6882 - val_multif0_mean_squared_error: 0.2432 - val_multif0_soft_binary_accuracy: 0.9901 - val_vocal_mean_squared_error: 0.2467 - val_vocal_soft_binary_accuracy: 0.9959\n",
      "Epoch 4/5\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 2.1555 - multif0_loss: 0.6773 - vocal_loss: 0.8008 - multif0_mean_squared_error: 0.2407 - multif0_soft_binary_accuracy: 0.6159 - vocal_mean_squared_error: 0.3078 - vocal_soft_binary_accuracy: 0.1714\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 00003: val_loss improved from 2.05586 to 2.04033, saving model to ../experiment_output/trialrun_multitask/model_weights.h5\n",
      "10/10 [==============================] - 0s - loss: 2.1544 - multif0_loss: 0.6771 - vocal_loss: 0.8003 - multif0_mean_squared_error: 0.2405 - multif0_soft_binary_accuracy: 0.6066 - vocal_mean_squared_error: 0.3076 - vocal_soft_binary_accuracy: 0.1697 - val_loss: 2.0403 - val_multif0_loss: 0.6796 - val_vocal_loss: 0.6811 - val_multif0_mean_squared_error: 0.2409 - val_multif0_soft_binary_accuracy: 0.9893 - val_vocal_mean_squared_error: 0.2431 - val_vocal_soft_binary_accuracy: 0.9962\n",
      "Epoch 5/5\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 2.1165 - multif0_loss: 0.6714 - vocal_loss: 0.7738 - multif0_mean_squared_error: 0.2381 - multif0_soft_binary_accuracy: 0.7907 - vocal_mean_squared_error: 0.2939 - vocal_soft_binary_accuracy: 0.2495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEpoch 00004: val_loss improved from 2.04033 to 2.02170, saving model to ../experiment_output/trialrun_multitask/model_weights.h5\n",
      "10/10 [==============================] - 0s - loss: 2.1135 - multif0_loss: 0.6711 - vocal_loss: 0.7714 - multif0_mean_squared_error: 0.2379 - multif0_soft_binary_accuracy: 0.8108 - vocal_mean_squared_error: 0.2926 - vocal_soft_binary_accuracy: 0.2380 - val_loss: 2.0217 - val_multif0_loss: 0.6751 - val_vocal_loss: 0.6715 - val_multif0_mean_squared_error: 0.2389 - val_multif0_soft_binary_accuracy: 0.9908 - val_vocal_mean_squared_error: 0.2385 - val_vocal_soft_binary_accuracy: 0.9968\n",
      "Computing Multif0 Metrics...\n",
      "    > Getting best threshold...\n",
      "    > 1 / 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rmb456/anaconda2/lib/python2.7/site-packages/mir_eval/multipitch.py:410: UserWarning: Estimate times not equal to reference times. Resampling to common time base.\n",
      "  warnings.warn(\"Estimate times not equal to reference times. \"\n",
      "/home/rmb456/anaconda2/lib/python2.7/site-packages/mir_eval/multipitch.py:275: UserWarning: Estimate frequencies are all empty.\n",
      "  warnings.warn(\"Estimate frequencies are all empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    > 2 / 27\n",
      "    > 3 / 27\n",
      "    > 4 / 27\n",
      "    > 5 / 27\n",
      "    > 6 / 27\n",
      "    > 7 / 27\n",
      "    > 8 / 27\n",
      "    > 9 / 27\n",
      "    > 10 / 27\n",
      "    > 11 / 27\n",
      "    > 12 / 27\n",
      "    > 13 / 27\n",
      "    > 14 / 27\n",
      "    > 15 / 27\n",
      "    > 16 / 27\n",
      "    > 17 / 27\n",
      "    > 18 / 27\n",
      "    > 19 / 27\n",
      "    > 20 / 27\n",
      "    > 21 / 27\n",
      "    > 22 / 27\n",
      "    > 23 / 27\n",
      "    > 24 / 27\n",
      "    > 25 / 27\n",
      "    > 26 / 27\n",
      "    > 27 / 27\n",
      "Best Threshold is 0.1\n",
      "Best validation accuracy is 0.0\n",
      "Validation accuracy at 0.5 is 0.0\n",
      "    > Scoring on bach10...\n",
      "    > 1 / 10\n",
      "    > 2 / 10\n",
      "    > 3 / 10\n",
      "    > 4 / 10\n",
      "    > 5 / 10\n",
      "    > 6 / 10\n",
      "    > 7 / 10\n",
      "    > 8 / 10\n",
      "    > 9 / 10\n",
      "    > 10 / 10\n",
      "       Precision  Recall  Accuracy  Substitution Error  Miss Error  \\\n",
      "count       10.0    10.0      10.0           10.000000   10.000000   \n",
      "mean         0.0     0.0       0.0            0.035384    0.964616   \n",
      "std          0.0     0.0       0.0            0.008367    0.008367   \n",
      "min          0.0     0.0       0.0            0.020123    0.951424   \n",
      "25%          0.0     0.0       0.0            0.029913    0.959346   \n",
      "50%          0.0     0.0       0.0            0.034648    0.965352   \n",
      "75%          0.0     0.0       0.0            0.040654    0.970087   \n",
      "max          0.0     0.0       0.0            0.048576    0.979877   \n",
      "\n",
      "       False Alarm Error  Total Error  Chroma Precision  Chroma Recall  \\\n",
      "count          10.000000    10.000000         10.000000      10.000000   \n",
      "mean            0.001569     1.001569          0.350749       0.012678   \n",
      "std             0.000733     0.000733          0.190733       0.007453   \n",
      "min             0.000427     1.000427          0.123950       0.005585   \n",
      "25%             0.001134     1.001134          0.186145       0.006527   \n",
      "50%             0.001374     1.001374          0.304516       0.010852   \n",
      "75%             0.002290     1.002290          0.548561       0.016652   \n",
      "max             0.002564     1.002564          0.611570       0.025162   \n",
      "\n",
      "       Chroma Accuracy  Chroma Substitution Error  Chroma Miss Error  \\\n",
      "count        10.000000                  10.000000          10.000000   \n",
      "mean          0.012409                   0.022706           0.964616   \n",
      "std           0.007335                   0.009651           0.008367   \n",
      "min           0.005373                   0.007162           0.951424   \n",
      "25%           0.006346                   0.015796           0.959346   \n",
      "50%           0.010579                   0.025637           0.965352   \n",
      "75%           0.016443                   0.028553           0.970087   \n",
      "max           0.024766                   0.038527           0.979877   \n",
      "\n",
      "       Chroma False Alarm Error  Chroma Total Error  \n",
      "count                 10.000000           10.000000  \n",
      "mean                   0.001569            0.988892  \n",
      "std                    0.000733            0.007075  \n",
      "min                    0.000427            0.976029  \n",
      "25%                    0.001134            0.985897  \n",
      "50%                    0.001374            0.990565  \n",
      "75%                    0.002290            0.994584  \n",
      "max                    0.002564            0.995362  \n",
      "    > Scoring on maps...\n",
      "    > 1 / 270\n",
      "    > 2 / 270\n",
      "    > 3 / 270\n",
      "    > 4 / 270\n",
      "    > 5 / 270\n",
      "    > 6 / 270\n",
      "    > 7 / 270\n",
      "    > 8 / 270\n",
      "    > 9 / 270\n",
      "    > 10 / 270\n",
      "    > 11 / 270\n",
      "    > 12 / 270\n",
      "    > 13 / 270\n",
      "    > 14 / 270\n",
      "    > 15 / 270\n",
      "    > 16 / 270\n",
      "    > 17 / 270\n",
      "    > 18 / 270\n",
      "    > 19 / 270\n",
      "    > 20 / 270\n",
      "    > 21 / 270\n",
      "    > 22 / 270\n",
      "    > 23 / 270\n",
      "    > 24 / 270\n",
      "    > 25 / 270\n",
      "    > 26 / 270\n",
      "    > 27 / 270\n",
      "    > 28 / 270\n",
      "    > 29 / 270\n",
      "    > 30 / 270\n",
      "    > 31 / 270\n",
      "    > 32 / 270\n",
      "    > 33 / 270\n",
      "    > 34 / 270\n",
      "    > 35 / 270\n",
      "    > 36 / 270\n",
      "    > 37 / 270\n",
      "    > 38 / 270\n",
      "    > 39 / 270\n",
      "    > 40 / 270\n",
      "    > 41 / 270\n",
      "    > 42 / 270\n",
      "    > 43 / 270\n",
      "    > 44 / 270\n",
      "    > 45 / 270\n",
      "    > 46 / 270\n",
      "    > 47 / 270\n",
      "    > 48 / 270\n",
      "    > 49 / 270\n",
      "    > 50 / 270\n",
      "    > 51 / 270\n",
      "    > 52 / 270\n",
      "    > 53 / 270\n",
      "    > 54 / 270\n",
      "    > 55 / 270\n",
      "    > 56 / 270\n",
      "    > 57 / 270\n",
      "    > 58 / 270\n",
      "    > 59 / 270\n",
      "    > 60 / 270\n",
      "    > 61 / 270\n",
      "    > 62 / 270\n",
      "    > 63 / 270\n",
      "    > 64 / 270\n",
      "    > 65 / 270\n",
      "    > 66 / 270\n",
      "    > 67 / 270\n",
      "    > 68 / 270\n",
      "    > 69 / 270\n",
      "    > 70 / 270\n",
      "    > 71 / 270\n",
      "    > 72 / 270\n",
      "    > 73 / 270\n",
      "    > 74 / 270\n",
      "    > 75 / 270\n",
      "    > 76 / 270\n",
      "    > 77 / 270\n",
      "    > 78 / 270\n",
      "    > 79 / 270\n",
      "    > 80 / 270\n",
      "    > 81 / 270\n",
      "    > 82 / 270\n",
      "    > 83 / 270\n",
      "    > 84 / 270\n",
      "    > 85 / 270\n",
      "    > 86 / 270\n",
      "    > 87 / 270\n",
      "    > 88 / 270\n",
      "    > 89 / 270\n",
      "    > 90 / 270\n",
      "    > 91 / 270\n",
      "    > 92 / 270\n",
      "    > 93 / 270\n",
      "    > 94 / 270\n",
      "    > 95 / 270\n",
      "    > 96 / 270\n",
      "    > 97 / 270\n",
      "    > 98 / 270\n",
      "    > 99 / 270\n",
      "    > 100 / 270\n",
      "    > 101 / 270\n",
      "    > 102 / 270\n",
      "    > 103 / 270\n",
      "    > 104 / 270\n",
      "    > 105 / 270\n",
      "    > 106 / 270\n",
      "    > 107 / 270\n",
      "    > 108 / 270\n",
      "    > 109 / 270\n",
      "    > 110 / 270\n",
      "    > 111 / 270\n",
      "    > 112 / 270\n",
      "    > 113 / 270\n",
      "    > 114 / 270\n",
      "    > 115 / 270\n",
      "    > 116 / 270\n",
      "    > 117 / 270\n",
      "    > 118 / 270\n",
      "    > 119 / 270\n",
      "    > 120 / 270\n",
      "    > 121 / 270\n",
      "    > 122 / 270\n",
      "    > 123 / 270\n",
      "    > 124 / 270\n",
      "    > 125 / 270\n",
      "    > 126 / 270\n",
      "    > 127 / 270\n",
      "    > 128 / 270\n",
      "    > 129 / 270\n",
      "    > 130 / 270\n",
      "    > 131 / 270\n",
      "    > 132 / 270\n",
      "    > 133 / 270\n",
      "    > 134 / 270\n",
      "    > 135 / 270\n",
      "    > 136 / 270\n",
      "    > 137 / 270\n",
      "    > 138 / 270\n",
      "    > 139 / 270\n",
      "    > 140 / 270\n",
      "    > 141 / 270\n",
      "    > 142 / 270\n",
      "    > 143 / 270\n",
      "    > 144 / 270\n",
      "    > 145 / 270\n",
      "    > 146 / 270\n",
      "    > 147 / 270\n",
      "    > 148 / 270\n",
      "    > 149 / 270\n",
      "    > 150 / 270\n",
      "    > 151 / 270\n",
      "    > 152 / 270\n",
      "    > 153 / 270\n",
      "    > 154 / 270\n",
      "    > 155 / 270\n",
      "    > 156 / 270\n",
      "    > 157 / 270\n",
      "    > 158 / 270\n",
      "    > 159 / 270\n",
      "    > 160 / 270\n",
      "    > 161 / 270\n",
      "    > 162 / 270\n",
      "    > 163 / 270\n",
      "    > 164 / 270\n",
      "    > 165 / 270\n",
      "    > 166 / 270\n",
      "    > 167 / 270\n",
      "    > 168 / 270\n",
      "    > 169 / 270\n",
      "    > 170 / 270\n",
      "    > 171 / 270\n",
      "    > 172 / 270\n",
      "    > 173 / 270\n",
      "    > 174 / 270\n",
      "    > 175 / 270\n",
      "    > 176 / 270\n",
      "    > 177 / 270\n",
      "    > 178 / 270\n",
      "    > 179 / 270\n",
      "    > 180 / 270\n",
      "    > 181 / 270\n",
      "    > 182 / 270\n",
      "    > 183 / 270\n",
      "    > 184 / 270\n",
      "    > 185 / 270\n",
      "    > 186 / 270\n",
      "    > 187 / 270\n",
      "    > 188 / 270\n",
      "    > 189 / 270\n",
      "    > 190 / 270\n",
      "    > 191 / 270\n",
      "    > 192 / 270\n",
      "    > 193 / 270\n",
      "    > 194 / 270\n",
      "    > 195 / 270\n",
      "    > 196 / 270\n",
      "    > 197 / 270\n",
      "    > 198 / 270\n",
      "    > 199 / 270\n",
      "    > 200 / 270\n",
      "    > 201 / 270\n",
      "    > 202 / 270\n",
      "    > 203 / 270\n",
      "    > 204 / 270\n",
      "    > 205 / 270\n",
      "    > 206 / 270\n",
      "    > 207 / 270\n",
      "    > 208 / 270\n",
      "    > 209 / 270\n",
      "    > 210 / 270\n",
      "    > 211 / 270\n",
      "    > 212 / 270\n",
      "    > 213 / 270\n",
      "    > 214 / 270\n",
      "    > 215 / 270\n",
      "    > 216 / 270\n",
      "    > 217 / 270\n",
      "    > 218 / 270\n",
      "    > 219 / 270\n",
      "    > 220 / 270\n",
      "    > 221 / 270\n",
      "    > 222 / 270\n",
      "    > 223 / 270\n",
      "    > 224 / 270\n",
      "    > 225 / 270\n",
      "    > 226 / 270\n",
      "    > 227 / 270\n",
      "    > 228 / 270\n",
      "    > 229 / 270\n",
      "    > 230 / 270\n",
      "    > 231 / 270\n",
      "    > 232 / 270\n",
      "    > 233 / 270\n",
      "    > 234 / 270\n",
      "    > 235 / 270\n",
      "    > 236 / 270\n",
      "    > 237 / 270\n",
      "    > 238 / 270\n",
      "    > 239 / 270\n",
      "    > 240 / 270\n",
      "    > 241 / 270\n",
      "    > 242 / 270\n",
      "    > 243 / 270\n",
      "    > 244 / 270\n",
      "    > 245 / 270\n",
      "    > 246 / 270\n",
      "    > 247 / 270\n",
      "    > 248 / 270\n",
      "    > 249 / 270\n",
      "    > 250 / 270\n",
      "    > 251 / 270\n",
      "    > 252 / 270\n",
      "    > 253 / 270\n",
      "    > 254 / 270\n",
      "    > 255 / 270\n",
      "    > 256 / 270\n",
      "    > 257 / 270\n",
      "    > 258 / 270\n",
      "    > 259 / 270\n",
      "    > 260 / 270\n",
      "    > 261 / 270\n",
      "    > 262 / 270\n",
      "    > 263 / 270\n",
      "    > 264 / 270\n",
      "    > 265 / 270\n",
      "    > 266 / 270\n",
      "    > 267 / 270\n",
      "    > 268 / 270\n",
      "    > 269 / 270\n",
      "    > 270 / 270\n",
      "        Precision      Recall    Accuracy  Substitution Error  Miss Error  \\\n",
      "count  270.000000  270.000000  270.000000          270.000000  270.000000   \n",
      "mean     0.006873    0.000044    0.000044            0.013484    0.986472   \n",
      "std      0.041475    0.000211    0.000210            0.010334    0.010321   \n",
      "min      0.000000    0.000000    0.000000            0.000542    0.941599   \n",
      "25%      0.000000    0.000000    0.000000            0.005728    0.981190   \n",
      "50%      0.000000    0.000000    0.000000            0.010345    0.989607   \n",
      "75%      0.000000    0.000000    0.000000            0.018810    0.994162   \n",
      "max      0.504983    0.002469    0.002459            0.058401    0.999458   \n",
      "\n",
      "       False Alarm Error  Total Error  Chroma Precision  Chroma Recall  \\\n",
      "count         270.000000   270.000000        270.000000     270.000000   \n",
      "mean            0.001044     1.001000          0.274878       0.003706   \n",
      "std             0.003199     0.003210          0.174089       0.003792   \n",
      "min             0.000000     0.997531          0.000000       0.000000   \n",
      "25%             0.000014     1.000000          0.123089       0.001224   \n",
      "50%             0.000137     1.000127          0.280581       0.002416   \n",
      "75%             0.000473     1.000472          0.392733       0.004873   \n",
      "max             0.026530     1.026530          0.883721       0.020664   \n",
      "\n",
      "       Chroma Accuracy  Chroma Substitution Error  Chroma Miss Error  \\\n",
      "count       270.000000                 270.000000         270.000000   \n",
      "mean          0.003653                   0.009822           0.986472   \n",
      "std           0.003719                   0.008230           0.010321   \n",
      "min           0.000000                   0.000278           0.941599   \n",
      "25%           0.001220                   0.004015           0.981190   \n",
      "50%           0.002406                   0.007347           0.989607   \n",
      "75%           0.004744                   0.013554           0.994162   \n",
      "max           0.020181                   0.051046           0.999458   \n",
      "\n",
      "       Chroma False Alarm Error  Chroma Total Error  \n",
      "count                270.000000          270.000000  \n",
      "mean                   0.001044            0.997338  \n",
      "std                    0.003199            0.004609  \n",
      "min                    0.000000            0.979910  \n",
      "25%                    0.000014            0.996037  \n",
      "50%                    0.000137            0.997967  \n",
      "75%                    0.000473            0.999361  \n",
      "max                    0.026530            1.019175  \n",
      "    > Scoring on medleydb_multif0...\n",
      "    > 1 / 16\n",
      "    > 2 / 16\n",
      "    > 3 / 16\n",
      "    > 4 / 16\n",
      "    > 5 / 16\n",
      "    > 6 / 16\n",
      "    > 7 / 16\n",
      "    > 8 / 16\n",
      "    > 9 / 16\n",
      "    > 10 / 16\n",
      "    > 11 / 16\n",
      "    > 12 / 16\n",
      "    > 13 / 16\n",
      "    > 14 / 16\n",
      "    > 15 / 16\n",
      "    > 16 / 16\n",
      "       Precision  Recall  Accuracy  Substitution Error  Miss Error  \\\n",
      "count       16.0    16.0      16.0           16.000000   16.000000   \n",
      "mean         0.0     0.0       0.0            0.032612    0.967388   \n",
      "std          0.0     0.0       0.0            0.030020    0.030020   \n",
      "min          0.0     0.0       0.0            0.010030    0.875745   \n",
      "25%          0.0     0.0       0.0            0.013684    0.965401   \n",
      "50%          0.0     0.0       0.0            0.020049    0.979951   \n",
      "75%          0.0     0.0       0.0            0.034599    0.986316   \n",
      "max          0.0     0.0       0.0            0.124255    0.989970   \n",
      "\n",
      "       False Alarm Error  Total Error  Chroma Precision  Chroma Recall  \\\n",
      "count          16.000000    16.000000         16.000000      16.000000   \n",
      "mean            0.008303     1.008303          0.106099       0.004452   \n",
      "std             0.007802     0.007802          0.066536       0.004791   \n",
      "min             0.000040     1.000040          0.016667       0.000211   \n",
      "25%             0.002904     1.002904          0.058328       0.001616   \n",
      "50%             0.005915     1.005915          0.078808       0.003353   \n",
      "75%             0.013002     1.013002          0.149896       0.005141   \n",
      "max             0.029601     1.029601          0.225989       0.020095   \n",
      "\n",
      "       Chroma Accuracy  Chroma Substitution Error  Chroma Miss Error  \\\n",
      "count        16.000000                  16.000000          16.000000   \n",
      "mean          0.004240                   0.028160           0.967388   \n",
      "std           0.004485                   0.027509           0.030020   \n",
      "min           0.000208                   0.009027           0.875745   \n",
      "25%           0.001567                   0.012198           0.965401   \n",
      "50%           0.003293                   0.018020           0.979951   \n",
      "75%           0.004781                   0.028682           0.986316   \n",
      "max           0.018801                   0.118296           0.989970   \n",
      "\n",
      "       Chroma False Alarm Error  Chroma Total Error  \n",
      "count                 16.000000           16.000000  \n",
      "mean                   0.008303            1.003851  \n",
      "std                    0.007802            0.008208  \n",
      "min                    0.000040            0.992823  \n",
      "25%                    0.002904            0.999740  \n",
      "50%                    0.005915            1.001879  \n",
      "75%                    0.013002            1.005603  \n",
      "max                    0.029601            1.025890  \n",
      "    > Scoring on su...\n",
      "    > 1 / 10\n",
      "    > 2 / 10\n",
      "    > 3 / 10\n",
      "    > 4 / 10\n",
      "    > 5 / 10\n",
      "    > 6 / 10\n",
      "    > 7 / 10\n",
      "    > 8 / 10\n",
      "    > 9 / 10\n",
      "    > 10 / 10\n",
      "       Precision  Recall  Accuracy  Substitution Error  Miss Error  \\\n",
      "count       10.0    10.0      10.0           10.000000   10.000000   \n",
      "mean         0.0     0.0       0.0            0.023698    0.976302   \n",
      "std          0.0     0.0       0.0            0.020079    0.020079   \n",
      "min          0.0     0.0       0.0            0.000577    0.925959   \n",
      "25%          0.0     0.0       0.0            0.016377    0.973596   \n",
      "50%          0.0     0.0       0.0            0.017679    0.982321   \n",
      "75%          0.0     0.0       0.0            0.026404    0.983623   \n",
      "max          0.0     0.0       0.0            0.074041    0.999423   \n",
      "\n",
      "       False Alarm Error  Total Error  Chroma Precision  Chroma Recall  \\\n",
      "count          10.000000    10.000000         10.000000      10.000000   \n",
      "mean            0.000601     1.000601          0.147115       0.004528   \n",
      "std             0.001037     0.001037          0.153794       0.007482   \n",
      "min             0.000000     1.000000          0.000000       0.000000   \n",
      "25%             0.000000     1.000000          0.018083       0.000322   \n",
      "50%             0.000000     1.000000          0.094183       0.002188   \n",
      "75%             0.001151     1.001151          0.283528       0.004700   \n",
      "max             0.002917     1.002917          0.379845       0.024905   \n",
      "\n",
      "       Chroma Accuracy  Chroma Substitution Error  Chroma Miss Error  \\\n",
      "count        10.000000                  10.000000          10.000000   \n",
      "mean          0.004371                   0.019171           0.976302   \n",
      "std           0.007112                   0.013942           0.020079   \n",
      "min           0.000000                   0.000577           0.925959   \n",
      "25%           0.000316                   0.012130           0.973596   \n",
      "50%           0.002137                   0.016336           0.982321   \n",
      "75%           0.004601                   0.022616           0.983623   \n",
      "max           0.023672                   0.049136           0.999423   \n",
      "\n",
      "       Chroma False Alarm Error  Chroma Total Error  \n",
      "count                 10.000000           10.000000  \n",
      "mean                   0.000601            0.996073  \n",
      "std                    0.001037            0.006719  \n",
      "min                    0.000000            0.978012  \n",
      "25%                    0.000000            0.996260  \n",
      "50%                    0.000000            0.997812  \n",
      "75%                    0.001151            0.999740  \n",
      "max                    0.002917            1.001255  \n",
      "    > Getting best threshold...\n",
      "    > 1 / 6\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-47914f7006bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtask_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmux_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m/scratch/rmb456/multif0/deepsalience/multitask_experiment.pyc\u001b[0m in \u001b[0;36mmain\u001b[0;34m(model, output_path, loss_weights, sample_weight_mode, task_indices, data_types, tasks, mux_weights, samples_per_epoch, nb_epochs, nb_val_samples)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mthresholds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mME\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mME\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/rmb456/multif0/deepsalience/multitask_evaluate.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, tasks, task_indices)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'vocal'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"    > Getting best threshold...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mbest_thresh_vocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_best_thresh_singlef0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vocal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mthresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vocal'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_thresh_vocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/rmb456/multif0/deepsalience/multitask_evaluate.py\u001b[0m in \u001b[0;36mget_best_thresh_singlef0\u001b[0;34m(model, task)\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mpredicted_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'vocal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mpredicted_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mtemp_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_freqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmir_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_time_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "multitask_experiment.main(\n",
    "    model, output_path, loss_weights, sample_weight_mode,\n",
    "    task_indices, data_types=data_types, tasks=tasks, mux_weights=None,\n",
    "    samples_per_epoch=10, nb_epochs=5, nb_val_samples=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
